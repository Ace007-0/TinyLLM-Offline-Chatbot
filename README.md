# TinyLLM-Offline-Chatbot
This is a lightweight offline chatbot interface built with [Streamlit](https://streamlit.io/) that interacts with a locally hosted **TinyLLM** model using HuggingFace Transformers. It allows users to input questions and receive responses from a locally fine-tuned language model â€” without needing an internet connection once the model is downloaded.

---

## ğŸš€ Features

- ğŸ’¬ Interactive chatbot UI built using Streamlit
- ğŸ§  Answers generated by a locally hosted TinyLLM model
- ğŸ”Œ Fully offline once the model is downloaded
- ğŸ§¾ Maintains chat history in the current session
- âŒ Type `Bye Bot` to clear the session and stop interaction

---

## ğŸ› ï¸ Requirements

- Python 3.8+
- [Transformers](https://pypi.org/project/transformers/)
- [Streamlit](https://pypi.org/project/streamlit/)
- PyTorch (matching your system's hardware â€” CPU or CUDA version)

---

## ğŸ“¦ Installation

 **Clone the repository**:
git clone https://github.com/your-username/tinyllm-offline-chatbot.git
cd tinyllm-offline-chatbot

## â–¶ï¸ Run the App
streamlit run app.py
Then open http://localhost:8501 in your browser.

## ğŸ“ Example Usage
You: How does gravity work?

Bot: Gravity is the force by which a planet or other body draws objects toward its center...

You: Bye Bot

Bot: Goodbye! Bot is shutting down.

## ğŸ“° Coming Soon: Full Medium Blog Tutorial
For a more detailed walkthrough, including how to download and run TinyLLM locally on your PC, a step-by-step guide will be published soon on my Medium blog.

This blog post will include:

ğŸ”½ How to download TinyLLM from Hugging Face

ğŸ’¾ How to store and manage model files locally

ğŸ› ï¸ How to integrate the model with your own applications

ğŸ§ª Tips for testing and customizing responses

âš™ï¸ How to make the chatbot fully offline

ğŸ“Œ Stay tuned! The link will be added here once the article is live.
